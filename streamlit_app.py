import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import glob
import time
import random
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from streamlit_option_menu import option_menu

# ========== åˆå§‹åŒ–è¨­å®š ==========
st.set_page_config(
    page_title="Spam Classifier Pro",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ========== å…¨åŸŸè·¯å¾‘è¨­å®š ==========
MODELS_DIR = "models"
VECTORIZER_PATH = "tfidf_vectorizer.pkl"
DATA_PATH = "sms_spam_no_header.csv"

# ========== è³‡æºè¼‰å…¥å‡½å¼ (å¿«å–) ==========
@st.cache_data
def load_data():
    """è¼‰å…¥ä¸¦é è™•ç†è³‡æ–™é›†"""
    if not os.path.exists(DATA_PATH):
        st.error(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™é›† {DATA_PATH}ï¼")
        return None
    df = pd.read_csv(DATA_PATH, encoding="latin-1")
    if len(df.columns) >= 2:
        df.columns = ["label", "message"] + list(df.columns[2:])
        df = df[["label", "message"]]
        df["label_num"] = df["label"].map({"ham": 0, "spam": 1})
    else:
        st.error("âš ï¸ CSV çµæ§‹ä¸ç¬¦ï¼Œéœ€åŒ…å« label, message æ¬„ä½ã€‚")
        return None
    return df

@st.cache_resource
def load_vectorizer():
    """è¼‰å…¥ TF-IDF å‘é‡åŒ–å·¥å…·"""
    if not os.path.exists(VECTORIZER_PATH):
        return None
    return joblib.load(VECTORIZER_PATH)

@st.cache_resource
def load_models():
    """å¾ 'models' è³‡æ–™å¤¾è¼‰å…¥æ‰€æœ‰æ¨¡å‹"""
    models = {}
    model_files = glob.glob(os.path.join(MODELS_DIR, "*.pkl"))
    if not model_files:
        return None
    for model_path in model_files:
        model_name = os.path.basename(model_path).replace("_model.pkl", "").replace("_", " ").title()
        models[model_name] = joblib.load(model_path)
    return models

# ========== å´é‚Šé¸å–® ==========
with st.sidebar:
    st.title(" Spam Classifier Pro")
    selected = option_menu(
        menu_title="ä¸»é¸å–®",
        options=["Live Prediction", "Batch Prediction", "Model Comparison", "Exploratory Data Analysis"],
        icons=["cpu", "upload", "bar-chart-steps", "pie-chart"],
        menu_icon="cast",
        default_index=0,
    )
    
    st.info("""å°ˆæ¡ˆå·²å‡ç´šï¼ç¾åœ¨æ‚¨å¯ä»¥ï¼š
- å³æ™‚æ¸¬è©¦å¤šç¨®æ¨¡å‹
- æ¯”è¼ƒå„æ¨¡å‹æ•ˆèƒ½
- é€²è¡Œæ·±å…¥çš„è³‡æ–™åˆ†æ""")

# ========== è¼‰å…¥æ ¸å¿ƒå…ƒä»¶ ==========
df = load_data()
vectorizer = load_vectorizer()
models = load_models()

if df is None or vectorizer is None or models is None:
    st.error("âŒ æ ¸å¿ƒå…ƒä»¶è¼‰å…¥å¤±æ•—ï¼è«‹å…ˆåŸ·è¡Œ `5114050013_hw3.py` è¨“ç·´è…³æœ¬ã€‚")
    st.stop()

# ========== é é¢è·¯ç”± ==========

# --- 1. å³æ™‚é æ¸¬ (Live Prediction) ---
if selected == "Live Prediction":
    st.title("ğŸ’¬ Live Text Prediction")

    # è™•ç†å›é¥‹è¨Šæ¯
    if st.session_state.get('feedback_success', False):
        st.balloons()
        st.success("å¤ªæ£’äº†ï¼æ„Ÿè¬æ‚¨çš„æ­£é¢å›é¥‹ã€‚")
        st.session_state.feedback_success = False # é¡¯ç¤ºä¸€æ¬¡å¾Œé‡è¨­

    st.markdown("å¾ä¸‹æ‹‰é¸å–®ä¸­é¸æ“‡ä¸€å€‹æ¨¡å‹ï¼Œç„¶å¾Œè¼¸å…¥æ‚¨æƒ³æ¸¬è©¦çš„è¨Šæ¯ã€‚")

    # åˆå§‹åŒ– session state
    if 'message_input' not in st.session_state:
        st.session_state.message_input = "Congratulations! You've won a $1,000 gift card. Click here to claim."

    def set_example_text(label):
        """Callback function to update the text area's content."""
        sample = df[df['label'] == label].sample(1).iloc[0]
        st.session_state.message_input = sample['message']

    model_name = st.selectbox("**é¸æ“‡æ¨¡å‹**", models.keys())
    
    # å°‡ text_area ç›´æ¥ç¶å®šåˆ° session_state
    st.text_area("**è¼¸å…¥è¦åˆ†é¡çš„è¨Šæ¯ï¼š**", height=150, key="message_input")

    col1, col2 = st.columns(2)
    with col1:
        st.button("ğŸ² è¼‰å…¥æ­£å¸¸éƒµä»¶ç¯„ä¾‹ (Ham)", on_click=set_example_text, args=('ham',), use_container_width=True)
    with col2:
        st.button("ğŸ² è¼‰å…¥åƒåœ¾éƒµä»¶ç¯„ä¾‹ (Spam)", on_click=set_example_text, args=('spam',), use_container_width=True)

    if st.button("ğŸ” åˆ†æè¨Šæ¯", use_container_width=True, type="primary"):
        # å¾ session_state è®€å–è¦åˆ†æçš„è¨Šæ¯
        message_to_analyze = st.session_state.message_input
        if message_to_analyze:
            model = models[model_name]
            message_tfidf = vectorizer.transform([message_to_analyze])
            
            prediction = model.predict(message_tfidf)[0]
            probability = model.predict_proba(message_tfidf)[0]
            
            # å°‡çµæœä¹Ÿå­˜å…¥ session_state ä»¥ä¾¿åœ¨é é¢åˆ·æ–°å¾Œé¡¯ç¤º
            st.session_state.is_spam = (prediction == 1)
            st.session_state.model_name = model_name
            st.session_state.probability = probability[1]
            st.session_state.show_result = True
        else:
            st.warning("è«‹è¼¸å…¥è¨Šæ¯ä»¥é€²è¡Œåˆ†æã€‚")
            st.session_state.show_result = False

    # æ ¹æ“š session_state é¡¯ç¤ºçµæœï¼Œç¢ºä¿é é¢åˆ·æ–°å¾Œçµæœä¾ç„¶å­˜åœ¨
    if st.session_state.get('show_result', False):
        if st.session_state.is_spam:
            st.error(f"**é æ¸¬çµæœï¼šé€™æ˜¯åƒåœ¾è¨Šæ¯ (Spam)**", icon="ğŸš¨")
        else:
            st.success(f"**é æ¸¬çµæœï¼šé€™ä¸æ˜¯åƒåœ¾è¨Šæ¯ (Ham)**", icon="âœ…")
        
        st.metric(label=f"æ¨¡å‹ `{st.session_state.model_name}` é æ¸¬ç‚º Spam çš„æ©Ÿç‡", value=f"{st.session_state.probability:.2%}")

        st.divider()
        st.markdown("#### é€™å€‹é æ¸¬æº–ç¢ºå—ï¼Ÿ")
        feedback_col1, feedback_col2 = st.columns(2)
        with feedback_col1:
            if st.button("ğŸ‘ é æ¸¬æ­£ç¢º", use_container_width=True):
                st.session_state.feedback_success = True
                st.rerun() # ä½¿ç”¨ rerun ç¢ºä¿æ°£çƒç‰¹æ•ˆèƒ½æ­£ç¢ºè§¸ç™¼
        with feedback_col2:
            if st.button("ğŸ‘ é æ¸¬éŒ¯èª¤", use_container_width=True):
                st.toast("å–”ä¸ï¼æ„Ÿè¬æ‚¨çš„å›é¥‹ï¼Œæˆ‘å€‘æœƒåƒè€ƒé€™é …è³‡è¨Šä¾†æ”¹é€²æ¨¡å‹ã€‚")
                st.info("æ‚¨çš„å›é¥‹å°æ–¼æå‡æ¨¡å‹æº–ç¢ºåº¦è‡³é—œé‡è¦ï¼")

# --- 2. æ‰¹æ¬¡é æ¸¬ (Batch Prediction) ---
elif selected == "Batch Prediction":
    st.title("ğŸ“¤ Batch Prediction with CSV")
    st.markdown("ä¸Šå‚³åŒ…å« `message` æ¬„ä½çš„ CSV æª”æ¡ˆï¼Œé¸æ“‡æ¨¡å‹å¾Œå³å¯é€²è¡Œæ•´æ‰¹é æ¸¬ã€‚")

    model_name = st.selectbox("é¸æ“‡æ¨¡å‹", models.keys())
    
    uploaded_file = st.file_uploader("ä¸Šå‚³æ‚¨çš„ CSV æª”æ¡ˆ", type=["csv"])

    if uploaded_file:
        test_df = pd.read_csv(uploaded_file)
        if "message" in test_df.columns:
            with st.spinner("ğŸ¤– æ­£åœ¨é€²è¡Œæ‰¹æ¬¡é æ¸¬..."):
                model = models[model_name]
                X_test = vectorizer.transform(test_df["message"])
                
                preds = model.predict(X_test)
                probs = model.predict_proba(X_test)[:, 1]
                
                result_df = test_df.copy()
                result_df["prediction"] = ["Spam" if p == 1 else "Ham" for p in preds]
                result_df["spam_probability"] = probs
                
                st.success("âœ… é æ¸¬å®Œæˆï¼")
                st.dataframe(result_df)
                
                @st.cache_data
                def convert_df_to_csv(df_to_convert):
                    return df_to_convert.to_csv(index=False).encode('utf-8')

                csv = convert_df_to_csv(result_df)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ",
                    data=csv,
                    file_name=f"predictions_{model_name.replace(' ', '_')}.csv",
                    mime="text/csv",
                )
        else:
            st.error("ä¸Šå‚³çš„ CSV æª”æ¡ˆä¸­å¿…é ˆåŒ…å« `message` æ¬„ä½ã€‚")

# --- 3. æ¨¡å‹æ¯”è¼ƒ (Model Comparison) ---
elif selected == "Model Comparison":
    st.title("ğŸ“Š Model Performance Comparison")
    st.markdown("èª¿æ•´ä¸‹æ–¹çš„æ¸¬è©¦é›†æ¯”ä¾‹ï¼Œæ•ˆèƒ½æŒ‡æ¨™å’Œåœ–è¡¨å°‡æœƒè‡ªå‹•æ›´æ–°ã€‚")

    test_size_ratio = st.slider("**å‹•æ…‹èª¿æ•´æ¸¬è©¦é›†æ¯”ä¾‹ (Test Set Ratio)**", 0.1, 0.5, 0.2, 0.05)

    @st.cache_data
    def get_performance_metrics(test_size):
        X_train, X_test, y_train, y_test = train_test_split(df["message"], df["label_num"], test_size=test_size, random_state=42)
        # æ³¨æ„ï¼šå‘é‡åŒ–å·¥å…·æ‡‰åœ¨è¨“ç·´é›†ä¸Š fitï¼Œç„¶å¾Œåœ¨æ¸¬è©¦é›†ä¸Š transform
        # ç‚ºç°¡åŒ–æ­¤è™•çš„å‹•æ…‹å±•ç¤ºï¼Œæˆ‘å€‘é‡è¤‡ä½¿ç”¨å·²è¨“ç·´å¥½çš„ vectorizer
        # åœ¨çœŸå¯¦å°ˆæ¡ˆä¸­ï¼Œæ‡‰åœ¨æ¯æ¬¡é‡åˆ‡è³‡æ–™æ™‚é‡æ–° fit vectorizer
        X_test_tfidf = vectorizer.transform(X_test)
        
        performance = []
        for name, model in models.items():
            start_time = time.time()
            y_pred = model.predict(X_test_tfidf)
            end_time = time.time()
            
            performance.append({
                "Model": name,
                "Accuracy": accuracy_score(y_test, y_pred),
                "Precision": precision_score(y_test, y_pred),
                "Recall": recall_score(y_test, y_pred),
                "F1-Score": f1_score(y_test, y_pred),
                "Prediction Time (s)": end_time - start_time,
            })
        # ç‚ºäº†æ··æ·†çŸ©é™£ï¼Œæˆ‘å€‘éœ€è¦å›å‚³ y_test å’Œ X_test_tfidf
        return pd.DataFrame(performance), y_test, X_test_tfidf

    with st.spinner("å‹•æ…‹è©•ä¼°ä¸­ï¼Œè«‹ç¨å€™..."):
        perf_df, y_test_split, X_test_tfidf_split = get_performance_metrics(test_size_ratio)

    st.subheader(f"åŸºæ–¼ {test_size_ratio:.0%} æ¸¬è©¦è³‡æ–™çš„æ•ˆèƒ½æŒ‡æ¨™")
    st.dataframe(perf_df.set_index("Model"))

    st.subheader("F1-Score æ¯”è¼ƒåœ–")
    fig, ax = plt.subplots()
    sns.barplot(data=perf_df, x="F1-Score", y="Model", ax=ax, orient='h', palette="viridis")
    ax.set_xlabel("F1-Score")
    ax.set_ylabel("Model")
    ax.set_title("F1-Score by Model")
    st.pyplot(fig)
    
    st.divider()
    st.subheader("æ··æ·†çŸ©é™£ (Confusion Matrix) è©³ç´°åˆ†æ")
    cm_model_name = st.selectbox("**é¸æ“‡ä¸€å€‹æ¨¡å‹ä»¥æŸ¥çœ‹å…¶æ··æ·†çŸ©é™£**", models.keys(), key="cm_select")
    
    if cm_model_name:
        model = models[cm_model_name]
        y_pred = model.predict(X_test_tfidf_split)
        cm = confusion_matrix(y_test_split, y_pred)
        
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax, xticklabels=["Ham", "Spam"], yticklabels=["Ham", "Spam"])
        ax.set_xlabel("Predicted Label")
        ax.set_ylabel("True Label")
        ax.set_title(f"Confusion Matrix for {cm_model_name}")
        st.pyplot(fig)

# --- 4. æ¢ç´¢æ€§è³‡æ–™åˆ†æ (EDA) ---
elif selected == "Exploratory Data Analysis":
    st.title("ğŸ“ˆ Exploratory Data Analysis (EDA)")

    # é¡åˆ¥åˆ†ä½ˆ
    st.subheader("Class Distribution")
    fig, ax = plt.subplots()
    df["label"].value_counts().plot(kind='pie', ax=ax, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'salmon'])
    ax.set_ylabel('')
    ax.set_title("Spam vs. Ham")
    st.pyplot(fig)

    # è¨Šæ¯é•·åº¦åˆ†ä½ˆ
    st.subheader("Message Length Distribution")
    df['message_len'] = df['message'].apply(len)
    fig, ax = plt.subplots()
    sns.histplot(data=df, x='message_len', hue='label', multiple='stack', bins=50, ax=ax)
    ax.set_title("Distribution of Message Length")
    st.pyplot(fig)

    # æ–‡å­—é›²
    st.subheader("Word Clouds")
    max_words = st.slider("**é¸æ“‡æ–‡å­—é›²ä¸­çš„æœ€å¤§è©å½™æ•¸é‡**", 50, 500, 200, 50)
    
    @st.cache_data
    def generate_wordcloud(text_series, max_words_wc):
        text = " ".join(msg for msg in text_series)
        wordcloud = WordCloud(width=800, height=400, background_color="white", max_words=max_words_wc).generate(text)
        return wordcloud

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### Ham (Not Spam)")
        with st.spinner("æ­£åœ¨ç”Ÿæˆ 'Ham' æ–‡å­—é›²..."):
            ham_wc = generate_wordcloud(df[df["label"] == "ham"]["message"], max_words)
            fig, ax = plt.subplots()
            ax.imshow(ham_wc, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)
            
    with col2:
        st.markdown("#### Spam")
        with st.spinner("æ­£åœ¨ç”Ÿæˆ 'Spam' æ–‡å­—é›²..."):
            spam_wc = generate_wordcloud(df[df["label"] == "spam"]["message"], max_words)
            fig, ax = plt.subplots()
            ax.imshow(spam_wc, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)